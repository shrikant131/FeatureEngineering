{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering on DK Housing Prices Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of Attribute Types"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr, zscore\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dk_housing_prices.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "missing_data[missing_data > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Handling missing data is crucial to ensure the integrity of the dataset. We will use different techniques such as imputation or removal based on the nature and amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Impute missing data with mean for numeric columns and mode for categorical columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna({col: df[col].mode()[0]}, inplace=True)\n",
    "    else:\n",
    "        df[col].fillna({col: df[col].mean()}, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization of Numeric Attributes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Normalize numeric attributes using z-score normalization\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].apply(zscore)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Normalization is performed to scale the numeric attributes to have a mean of 0 and a standard deviation of 1. This helps in improving the performance of machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the 5 Most Expensive Cities and Cities with Maximum Unique Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5 most expensive cities\n",
    "expensive_cities = df.groupby('city')['purchase_price'].mean().sort_values(ascending=False).head(5)\n",
    "expensive_cities"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5 cities with maximum unique zip codes\n",
    "unique_zip_cities = df.groupby('city')['zip_code'].nunique().sort_values(ascending=False).head(5)\n",
    "unique_zip_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Analyzing the most expensive cities and cities with maximum unique zip codes helps in understanding the distribution of house prices and the diversity of locations in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximity Measures"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Proximity measure between house_type and sqm\n",
    "house_type_sqm = df.groupby('house_type')['sqm'].mean()\n",
    "house_type_sqm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Proximity measure between house_type and purchase_price\n",
    "house_type_price = df.groupby('house_type')['purchase_price'].mean()\n",
    "house_type_price"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Proximity measure between no_rooms and purchase_price\n",
    "rooms_price = df.groupby('no_rooms')['purchase_price'].mean()\n",
    "rooms_price"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Euclidean distance between numeric columns\n",
    "from scipy.spatial.distance import euclidean\n",
    "euclidean_distance = euclidean(df['sqm'], df['purchase_price'])\n",
    "euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Manhattan distance between numeric columns\n",
    "from scipy.spatial.distance import cityblock\n",
    "manhattan_distance = cityblock(df['sqm'], df['purchase_price'])\n",
    "manhattan_distance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cosine similarity between numeric columns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(df[['sqm']], df[['purchase_price']])\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mahalanobis distance between numeric columns\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "cov_matrix = np.cov(df[['sqm', 'purchase_price']].T)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "mahalanobis_distance = mahalanobis(df['sqm'], df['purchase_price'], inv_cov_matrix)\n",
    "mahalanobis_distance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dissimilarity matrix for categorical columns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "dissimilarity_matrix = pairwise_distances(df[['house_type', 'sales_type']], metric='hamming')\n",
    "dissimilarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Proximity measures help in understanding the relationship between different attributes. For example, the average square meters and purchase price for each house type can provide insights into the market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Feature selection using filter methods\n",
    "\n",
    "# Define independent variables and target variable\n",
    "X = df.drop(columns=['purchase_price'])\n",
    "y = df['purchase_price']\n",
    "\n",
    "# Convert date column to datetime format and extract relevant features\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "X = df.drop(columns=['purchase_price', 'date'])\n",
    "\n",
    "# Apply SelectKBest with f_regression\n",
    "kbest_f = SelectKBest(score_func=f_regression, k=5)\n",
    "kbest_f.fit(X, y)\n",
    "features_f = X.columns[kbest_f.get_support()]\n",
    "features_f"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply SelectKBest with mutual_info_regression\n",
    "kbest_mi = SelectKBest(score_func=mutual_info_regression, k=5)\n",
    "kbest_mi.fit(X, y)\n",
    "features_mi = X.columns[kbest_mi.get_support()]\n",
    "features_mi"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply correlation method\n",
    "correlation = df.corr()\n",
    "correlation_target = abs(correlation['purchase_price'])\n",
    "relevant_features = correlation_target[correlation_target > 0.5]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply Pearson coefficient\n",
    "pearson_coefficients = df.corr(method='pearson')['purchase_price'].sort_values(ascending=False)\n",
    "pearson_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply Recursive Feature Elimination (RFE)\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "rfe.fit(X, y)\n",
    "features_rfe = X.columns[rfe.get_support()]\n",
    "features_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Feature selection is performed to identify the most relevant features for predicting the target variable. We use different filter methods such as f_regression, mutual_info_regression, correlation, Pearson coefficient, and Recursive Feature Elimination (RFE) to select the top features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare the top 5 features from each method\n",
    "comparison_df = pd.DataFrame({'f_regression': features_f, 'mutual_info_regression': features_mi, 'correlation': relevant_features.index, 'pearson': pearson_coefficients.index[:5], 'rfe': features_rfe})\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Comparing the top 5 features from each feature selection method helps in understanding the consistency and differences between the methods. This comparison provides insights into the most important features for predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot correlation between independent features and target variable\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Correlation plot helps in visualizing the relationship between different features and the target variable. It provides insights into the strength and direction of the relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations and Other Plots for Analysis and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Distribution of purchase prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['purchase_price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Purchase Prices')\n",
    "plt.xlabel('Purchase Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Boxplot of purchase prices by house type\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='house_type', y='purchase_price', data=df)\n",
    "plt.title('Boxplot of Purchase Prices by House Type')\n",
    "plt.xlabel('House Type')\n",
    "plt.ylabel('Purchase Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scatter plot of sqm vs purchase price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='sqm', y='purchase_price', data=df)\n",
    "plt.title('Scatter Plot of SQM vs Purchase Price')\n",
    "plt.xlabel('SQM')\n",
    "plt.ylabel('Purchase Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Visualizations such as histograms, boxplots, and scatter plots help in understanding the distribution and relationships of different attributes in the dataset. They provide valuable insights for data preprocessing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Handling outliers using z-score approach\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores for numeric columns\n",
    "z_scores = np.abs(zscore(df[numeric_cols]))\n",
    "\n",
    "# Set a threshold for z-scores\n",
    "threshold = 3\n",
    "\n",
    "# Identify outliers\n",
    "outliers = np.where(z_scores > threshold)\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[(z_scores < threshold).all(axis=1)]\n",
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Z-score approach is preferred for handling outliers because it standardizes the data and identifies outliers based on the number of standard deviations from the mean. This method is effective for normally distributed data and helps in maintaining the integrity of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques Used in Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identification of attribute types\n",
    "- Handling missing data using imputation\n",
    "- Normalization of numeric attributes\n",
    "- Analysis of most expensive cities and cities with maximum unique zip codes\n",
    "- Proximity measures between specified columns\n",
    "- Feature selection using filter methods (f_regression, mutual_info_regression, correlation, Pearson coefficient, RFE)\n",
    "- Comparison of feature selection methods\n",
    "- Correlation plot\n",
    "- Visualizations (histograms, boxplots, scatter plots)\n",
    "- Handling outliers using z-score approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we performed feature engineering tasks on the DK housing prices dataset. We started by identifying the types of attributes and handling missing data using imputation. We then normalized the numeric attributes to improve the performance of machine learning algorithms. We analyzed the 5 most expensive cities and cities with maximum unique zip codes to understand the distribution of house prices and the diversity of locations.\n",
    "\n",
    "We calculated proximity measures between house_type and sqm, house_type and purchase_price, and no_rooms and purchase_price to understand the relationship between different attributes. We performed feature selection using five filter methods (f_regression, mutual_info_regression, correlation, Pearson coefficient, and RFE) to identify the most relevant features for predicting the target variable. We also compared the top 5 features from each method to understand the consistency and differences between the methods. We plotted the correlation between independent features and the target variable to visualize the relationships.\n",
    "\n",
    "We created visualizations such as histograms, boxplots, and scatter plots to understand the distribution and relationships of different attributes in the dataset. We handled outliers using the z-score approach to maintain the integrity of the dataset. Finally, we summarized the techniques used in feature engineering, including identification of attribute types, handling missing data, normalization, analysis, proximity measures, feature selection, comparison of feature selection methods, correlation plot, visualizations, and handling outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasons for Handling Data for Each Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date\n",
    "The 'date' column represents the transaction date. It is important to retain this column as it provides temporal information about the transactions. No missing data handling is required for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quarter\n",
    "The 'quarter' column represents the quarter based on a standard calendar year. It is important to retain this column as it provides temporal information about the transactions. No missing data handling is required for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### house_id\n",
    "The 'house_id' column represents a unique house id. This column can be dropped as it does not provide any useful information for analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### house_type\n",
    "The 'house_type' column represents the type of house. It is important to retain this column as it provides categorical information about the type of house. Missing data in this column is imputed with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sales_type\n",
    "The 'sales_type' column represents the type of sale. It is important to retain this column as it provides categorical information about the type of sale. Missing data in this column is imputed with the mode. The '-' value is dropped as it does not provide any useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### year_build\n",
    "The 'year_build' column represents the year the house was built. It is important to retain this column as it provides temporal information about the age of the house. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### purchase_price\n",
    "The 'purchase_price' column represents the purchase price in DKK. It is important to retain this column as it is the target variable for modeling. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### %_change_between_offer_and_purchase\n",
    "The '%_change_between_offer_and_purchase' column represents the percentage change between the offer and purchase price. It is important to retain this column as it provides information about the negotiation process. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no_rooms\n",
    "The 'no_rooms' column represents the number of rooms. It is important to retain this column as it provides information about the size of the house. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqm\n",
    "The 'sqm' column represents the number of square meters. It is important to retain this column as it provides information about the size of the house. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqm_price\n",
    "The 'sqm_price' column represents the purchase price divided by the number of square meters. It is important to retain this column as it provides information about the price per square meter. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### address\n",
    "The 'address' column represents the address of the house. This column can be dropped as it does not provide any useful information for analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip_code\n",
    "The 'zip_code' column represents the zip code of the house. It is important to retain this column as it provides geographical information about the location of the house. Missing data in this column is imputed with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city\n",
    "The 'city' column represents the city of the house. It is important to retain this column as it provides geographical information about the location of the house. Missing data in this column is imputed with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### area\n",
    "The 'area' column represents the area of the house. It is important to retain this column as it provides geographical information about the location of the house. Missing data in this column is imputed with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### region\n",
    "The 'region' column represents the region of the house. It is important to retain this column as it provides geographical information about the location of the house. Missing data in this column is imputed with the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nom_interest_rate%\n",
    "The 'nom_interest_rate%' column represents the Danish nominal interest rate per quarter. It is important to retain this column as it provides economic information that may affect house prices. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dk_ann_infl_rate%\n",
    "The 'dk_ann_infl_rate%' column represents the Danish annual inflation rate per quarter. It is important to retain this column as it provides economic information that may affect house prices. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yield_on_mortgage_credit_bonds%\n",
    "The 'yield_on_mortgage_credit_bonds%' column represents the 30-year mortgage bond rate (without spread). It is important to retain this column as it provides economic information that may affect house prices. Missing data in this column is imputed with the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Most Important Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the feature selection methods, the most important feature for predicting the purchase price is the 'sqm' (square meters) of the house. This is because the size of the house is directly related to its value. Larger houses tend to have higher purchase prices, making 'sqm' a crucial factor in determining the price. Additionally, the 'sqm' feature consistently appeared in the top features selected by different methods, further emphasizing its importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Quarter Column"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Process the quarter column to ensure consistency\n",
    "df['quarter'] = df['quarter'].apply(lambda x: f'Q{x}' if isinstance(x, int) else x)\n",
    "df['quarter'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation: Processing the quarter column ensures consistency in the data format. This step converts integer values to a consistent string format (e.g., 'Q1', 'Q2', etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Tasks on DK Housing Prices Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains a Python notebook that performs feature engineering tasks on the DK housing prices dataset. The dataset contains residential household sales during the period 1992 - 2024. The feature engineering tasks include:\n",
    "\n",
    "- Identification of attribute types\n",
    "- Handling missing data\n",
    "- Normalization of numeric attributes\n",
    "- Analysis of the 5 most expensive cities and cities with maximum unique zip codes\n",
    "- Calculation of proximity measures between specified columns\n",
    "- Feature selection using filter methods (f_regression, mutual_info_regression, correlation)\n",
    "- Correlation plot\n",
    "- Visualizations (histograms, boxplots, scatter plots)\n",
    "- Handling outliers using the z-score approach"
   ]
  }
 ]
}
