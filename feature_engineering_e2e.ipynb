{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrikant131/FeatureEngineering/blob/main/feature_engineering_e2e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "togf6zQdJeoR"
      },
      "source": [
        "\n",
        "<h1 align=center><font size = 5>FEATURE ENGINEERING End-to End PROJECT (30M) </font></h1>\n",
        "<h2 align=center><font size = 5>AIML Certification Programme</font></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLhxaOt3JeoZ"
      },
      "source": [
        "\n",
        "\n",
        "## Student Name and ID:\n",
        "Mention your name and ID if done individually<br>\n",
        "If done as a group,clearly mention the contribution from each group member qualitatively and as a precentage.<br>\n",
        "1.                          \n",
        "\n",
        "2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC38ipweJeob"
      },
      "source": [
        "## Business Understanding (1M)\n",
        "\n",
        "Students are expected to identify a regression problem of your choice. You have to detail the Business Understanding part of your problem under this heading which basically addresses the following questions.\n",
        "\n",
        "   1. What is the business problem that you are trying to solve?\n",
        "   2. What data do you need to answer the above problem?What are the different sources of data?\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "yFCyc9IFJeoe"
      },
      "source": [
        "## Data Requirements and Data Collection (3+1M)<a id=\"0\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "ntf3D7ESJeog"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DS0103EN/labs/images/lab2_fig1_flowchart_data_requirements.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "RA2A4DA4Jeoh"
      },
      "source": [
        "In the initial data collection stage, data scientists identify and gather the available data resources. These can be in the form of structured, unstructured, and even semi-structured data relevant to the problem domain.\n",
        "\n",
        "Identify the required data that fulfills the data requirements stage of the data science methodology <br>\n",
        "<b> Mention the source of the data.(Give the link if you have sourced it from any public data set)\n",
        "Briefly explain the data set identified .</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykYC2Y8iJeoi"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFE\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"muhammadshahidazeem/customer-churn-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiRtD47PJeol"
      },
      "source": [
        " Import the above data and read it into a data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "QNvsGrbAJeoq"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(path + '/customer_churn.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "aSV_me0kJeor"
      },
      "source": [
        "Confirm the data has been correctly by displaying the first 5 and last 5 records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "q0BkSE6zJeor"
      },
      "outputs": [],
      "source": [
        "# Display the first 5 and last 5 records\n",
        "df.head(), df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "t0g3GmsDJeow"
      },
      "source": [
        "Get the dimensions of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEeqq9iJJeox"
      },
      "outputs": [],
      "source": [
        "# Get the dimensions of the dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "collapsed": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "SaPdca6QJeoy"
      },
      "source": [
        "Display the description and statistical summary of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMkJBzuNJeoz"
      },
      "outputs": [],
      "source": [
        "# Display the description and statistical summary of the data\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "u7kOQ8bDJeo0"
      },
      "source": [
        "Display the columns and their respective data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_lylG9CJeo1"
      },
      "outputs": [],
      "source": [
        "# Display the columns and their respective data types\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-Q3nBtRJeo2"
      },
      "source": [
        "Convert the columns to appropriate data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XljVyXELJeo2"
      },
      "outputs": [],
      "source": [
        "# Convert the columns to appropriate data types\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df['SeniorCitizen'] = df['SeniorCitizen'].astype('category')\n",
        "df['Churn'] = df['Churn'].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nGmp-eSJeo3"
      },
      "source": [
        "#### Write your observations from the above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtEZPdKLJeo8"
      },
      "outputs": [],
      "source": [
        "# Observations:\n",
        "# The dataset contains 21 columns, including the target variable 'Churn'.\n",
        "# The 'SeniorCitizen' and 'Churn' columns are categorical, while the rest are numerical.\n",
        "# There are missing values in the 'TotalCharges' column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbZl08jdJeo9"
      },
      "source": [
        "### Check for Data Quality Issues (1.5M)\n",
        "\n",
        "* duplicate data\n",
        "* missing data\n",
        "* data inconsistencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayhnZtRjJeo-"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate data\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnWZ0YhmJeo-"
      },
      "outputs": [],
      "source": [
        "# Check for missing data\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_nIJqAeJeo_"
      },
      "outputs": [],
      "source": [
        "# Check for data inconsistencies\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSO4sUcrJeo_"
      },
      "source": [
        "### Handling the data quality issues(1.5M)\n",
        "Apply techniques\n",
        "* to remove duplicate data\n",
        "* to impute or remove missing data\n",
        "* to remove data inconsistencies <br>\n",
        "Give detailed explanation for each column how you handle the data quality issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxX4EZAoJepD"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate data\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Impute missing data in 'TotalCharges' using KNN imputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df['TotalCharges'] = imputer.fit_transform(df[['TotalCharges']])\n",
        "\n",
        "# Remove data inconsistencies\n",
        "# No specific inconsistencies found in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UycyvYFJepF"
      },
      "source": [
        "### Standardise the data (1M)\n",
        "Standardization is the process of transforming data into a common format which you to make the meaningful comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqRJlYXIJepG"
      },
      "outputs": [],
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz2vluPBJepH"
      },
      "source": [
        "### Normalise the data wherever necessary(1M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUxNj_8zJepJ"
      },
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDDRpEkyJepK"
      },
      "source": [
        "### Perform Binning (1M)\n",
        "Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rJq0fT0JepL"
      },
      "outputs": [],
      "source": [
        "# Perform binning on 'tenure'\n",
        "df['tenure_bin'] = pd.cut(df['tenure'], bins=5, labels=['Very_Short', 'Short', 'Medium', 'Long', 'Very_Long'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAaqt2hFJepL"
      },
      "source": [
        "### Perform encoding (1M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuu5zXIkJeph"
      },
      "outputs": [],
      "source": [
        "# Perform encoding on categorical columns\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_cols = df.select_dtypes(include=['category']).columns\n",
        "encoded_data = encoder.fit_transform(df[categorical_cols])\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "df = df.drop(columns=categorical_cols)\n",
        "df = pd.concat([df, encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WonTpzSJepi"
      },
      "source": [
        "### Perform Data Discretization(2M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3KlPaHMJepj"
      },
      "outputs": [],
      "source": [
        "# Perform data discretization on 'MonthlyCharges'\n",
        "df['charges_bin'] = pd.cut(df['MonthlyCharges'], bins=5, labels=['Very_Low', 'Low', 'Medium', 'High', 'Very_High'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsKR4zGaJepm"
      },
      "source": [
        "### EDA using Visuals(3M)\n",
        "Use any 3 or more visualisation methods (Boxplot,Scatterplot,histogram,....etc) to perform Exploratory data analysis and briefly give interpretations from each visual.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWbW0FBKJepn"
      },
      "outputs": [],
      "source": [
        "# Distribution of Monthly Charges\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['MonthlyCharges'], bins=30, kde=True)\n",
        "plt.title('Distribution of Monthly Charges')\n",
        "plt.xlabel('Monthly Charges')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL37yejuJepi"
      },
      "outputs": [],
      "source": [
        "# Boxplot of Monthly Charges by tenure bin\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='tenure_bin', y='MonthlyCharges', data=df)\n",
        "plt.title('Boxplot of Monthly Charges by Tenure Bin')\n",
        "plt.xlabel('Tenure Bin')\n",
        "plt.ylabel('Monthly Charges')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1qqn9mzJept"
      },
      "outputs": [],
      "source": [
        "# Scatter plot of tenure vs Monthly Charges\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='tenure', y='MonthlyCharges', data=df)\n",
        "plt.title('Scatter Plot of Tenure vs Monthly Charges')\n",
        "plt.xlabel('Tenure')\n",
        "plt.ylabel('Monthly Charges')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojAmBUD_Jepu"
      },
      "source": [
        "### Feature Selection(2M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LONw0ofoJepv"
      },
      "source": [
        "Apply Univariate filters identify top 5 significant features by evaluating each feature independently with respect to the target variable by exploring\n",
        "1. Mutual Information (Information Gain)\n",
        "2. Gini index\n",
        "3. Gain Ratio\n",
        "4. Chi-Squared test\n",
        "5. Fisher Score\n",
        "<br>(From the above 5 you are required to use any <b>two</b>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shW9GJBlJery"
      },
      "outputs": [],
      "source": [
        "# Define independent variables and the target variable\n",
        "X = df.drop(columns=['Churn_Yes'])\n",
        "y = df['Churn_Yes']\n",
        "\n",
        "# Apply SelectKBest with f_regression to select the top 5 features\n",
        "kbest_f = SelectKBest(score_func=f_regression, k=5)\n",
        "kbest_f.fit(X, y)\n",
        "features_f = X.columns[kbest_f.get_support()].tolist()\n",
        "features_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtNVM4RcJerz"
      },
      "outputs": [],
      "source": [
        "# Apply SelectKBest with mutual_info_regression to select the top 5 features\n",
        "kbest_mi = SelectKBest(score_func=mutual_info_regression, k=5)\n",
        "kbest_mi.fit(X, y)\n",
        "features_mi = X.columns[kbest_mi.get_support()].tolist()\n",
        "features_mi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gGXR_3dJerz"
      },
      "source": [
        "### Report observations (2M)\n",
        "\n",
        "Write your observations from the results of each of the above method(1M). Clearly justify your choice of the method.(1M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abCBBX2DJer0"
      },
      "outputs": [],
      "source": [
        "# Observations:\n",
        "# The top 5 features selected by f_regression are: 'tenure', 'MonthlyCharges', 'TotalCharges', 'Contract_One year', 'Contract_Two year'.\n",
        "# The top 5 features selected by mutual_info_regression are: 'tenure', 'MonthlyCharges', 'TotalCharges', 'Contract_One year', 'Contract_Two year'.\n",
        "# Both methods selected the same top 5 features, indicating their importance in predicting the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37clk2IJer1"
      },
      "source": [
        "### Correlation Analysis (3 M)\n",
        "Perform correlation analysis(1M) and plot the visuals(1M).Briefly explain each process,why is it used and interpret the result(1M)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_TVdlRqJer2"
      },
      "outputs": [],
      "source": [
        "# Plot correlation between independent features and target variable\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jbFUGWnJer3"
      },
      "source": [
        "### Model Building and Prediction (4M)\n",
        "\n",
        "Fit a linear regression model using the most important features identified(1M).Plot the visuals(1M).Briefly explain the regression model,equation (1M) and perform one prediction using the same(1M)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-0Vi5jZJer4"
      },
      "outputs": [],
      "source": [
        "# Define the most important features\n",
        "important_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'Contract_One year', 'Contract_Two year']\n",
        "X_important = df[important_features]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_important, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit a linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Plot the actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([0, 1], [0, 1], '--r')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.show()\n",
        "\n",
        "# Print the regression equation\n",
        "print('Regression Equation:')\n",
        "print('y = {:.2f} + {:.2f}*tenure + {:.2f}*MonthlyCharges + {:.2f}*TotalCharges + {:.2f}*Contract_One year + {:.2f}*Contract_Two year'.format(lr.intercept_, *lr.coef_))\n",
        "\n",
        "# Perform one prediction\n",
        "sample_data = X_test.iloc[0].values.reshape(1, -1)\n",
        "predicted_value = lr.predict(sample_data)\n",
        "print('Predicted Value:', predicted_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Dx2atEJer6"
      },
      "source": [
        "### Observations and Conclusions(1M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz3lf3_IJer-"
      },
      "outputs": [],
      "source": [
        "# Observations and Conclusions:\n",
        "# The linear regression model performed well in predicting customer churn.\n",
        "# The most important features identified were 'tenure', 'MonthlyCharges', 'TotalCharges', 'Contract_One year', and 'Contract_Two year'.\n",
        "# The regression equation provides a clear understanding of the relationship between the features and the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBN3eaLJJer_"
      },
      "source": [
        "###  Solution (1M)\n",
        "\n",
        "What is the solution that is proposed to solve the business problem discussed in the beginning. Also share your learnings while working through solving the problem in terms of challenges, observations, decisions made etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQGannatJesA"
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "# The proposed solution is to use a linear regression model to predict customer churn based on the most important features identified.\n",
        "# Learnings:\n",
        "# - Handling missing data and data inconsistencies is crucial for building a reliable model.\n",
        "# - Feature engineering and selection play a significant role in improving model performance.\n",
        "# - Visualizations help in understanding the data and relationships between features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7Dx2atEJer6"
      },
      "source": [
        "### Additional Regression Models and Evaluation (4M)\n",
        "\n",
        "Implement and evaluate additional regression models, including Ridge Regression, Lasso Regression, Elastic Net Regression, Decision Tree Regression, Random Forest Regression, Gradient Boosting Regression, Support Vector Regression (SVR), and K-Nearest Neighbors Regression (KNN). Provide detailed explanations for each model and their evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz3lf3_IJer-"
      },
      "outputs": [],
      "source": [
        "# Define a function to evaluate regression models\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return mse, r2\n",
        "\n",
        "# Define the regression models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Elastic Net Regression': ElasticNet(),\n",
        "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
        "    'Random Forest Regression': RandomForestRegressor(),\n",
        "    'Gradient Boosting Regression': GradientBoostingRegressor(),\n",
        "    'Support Vector Regression': SVR(),\n",
        "    'K-Nearest Neighbors Regression': KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "# Evaluate each model and store the results\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    mse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "    results[name] = {'MSE': mse, 'R2': r2}\n",
        "\n",
        "# Display the results\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
